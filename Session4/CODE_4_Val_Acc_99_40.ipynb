{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CODE 4 - Val_Acc-99.40.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "outputId": "6f3afc93-f252-48c7-de3f-0979b50a2ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "127010f7-398a-45ad-f248-9c4edb09fdee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[7])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8f418a66a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "a2740943-ff16-4b55-98fb-8075e2f5aecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "d5050755-f083-4dcd-d973-ddb521d054fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1230
        }
      },
      "source": [
        "# Reduced total parameters using Kernal numbers, Batch normalization, max pooling, drop outs.\n",
        "# Used Scheduler to set learning rate and play around\n",
        "\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) #RF 26x26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # RF 24x24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) # RF 24x24\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#12\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))# RF 10x10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))# RF 8x8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))# RF 6x6\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))# RF 4x4\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 10)        170       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,072\n",
            "Trainable params: 12,892\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "37c214af-4285-4f4a-e21f-198765dd529e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1465
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.2160 - acc: 0.9311 - val_loss: 0.0533 - val_acc: 0.9836\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0674 - acc: 0.9792 - val_loss: 0.0403 - val_acc: 0.9863\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0503 - acc: 0.9840 - val_loss: 0.0326 - val_acc: 0.9889\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0443 - acc: 0.9864 - val_loss: 0.0254 - val_acc: 0.9923\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0387 - acc: 0.9878 - val_loss: 0.0289 - val_acc: 0.9898\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0282 - val_acc: 0.9904\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0334 - acc: 0.9893 - val_loss: 0.0246 - val_acc: 0.9914\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0307 - acc: 0.9903 - val_loss: 0.0254 - val_acc: 0.9910\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0287 - acc: 0.9908 - val_loss: 0.0216 - val_acc: 0.9933\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0268 - acc: 0.9912 - val_loss: 0.0225 - val_acc: 0.9925\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0241 - val_acc: 0.9914\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.0206 - val_acc: 0.9929\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0201 - val_acc: 0.9932\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.0212 - val_acc: 0.9931\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0206 - val_acc: 0.9927\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0205 - acc: 0.9934 - val_loss: 0.0184 - val_acc: 0.9934\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0188 - val_acc: 0.9940\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0201 - val_acc: 0.9937\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0203 - val_acc: 0.9928\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0190 - val_acc: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f34055c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "4123e45c-ede8-40b1-a36b-02748f31c053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01900654138001264, 0.9939]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}